{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15Z970-GA5BK\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pol_news.csv')\n",
    "ngram = pd.read_csv('news_ngram_updown.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_copy = ngram.copy()\n",
    "token_copy = df.copy()\n",
    "ngram_copy['token'] = token_copy['token']\n",
    "added_df = ngram_copy.drop(['Unnamed: 0', 'news_media', 'text', 'title', 'url', 'price'], axis = 1)\n",
    "added_df['ngrams'] = added_df['ngrams'].apply(lambda x: x.replace('[', '').replace(']', '').replace(\"'\", ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뭘 만든거지.. 허허 각 row에 같이 있는 ngram과 token을 동시에 합치는 방법을 구상해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fae8223f6654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0madded_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ngram_token'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0madded_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ngrams'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madded_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ngrams'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0madded_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ngram_token'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify_pos_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madded_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-fae8223f6654>\u001b[0m in \u001b[0;36mclassify_pos_tokens\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mup_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'up_down'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'상승'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "def classify_pos_tokens(dataframe):\n",
    "    a = 0\n",
    "    for up_down in dataframe['up_down']:\n",
    "        if up_down == '상승':\n",
    "            up_ngram = []\n",
    "            for ngram in dataframe[dataframe['up_down'] == '상승']['ngrams']:\n",
    "\n",
    "                split = ngram.split(',')\n",
    "                count = 0\n",
    "                if len(split) > 1:\n",
    "                    for count in range(len(split)):\n",
    "                        up_ngram.append(split[count])\n",
    "                    a += 1\n",
    "                    if a % 10000 == 0:\n",
    "                        print(a)\n",
    "            up_token = []\n",
    "            for token in dataframe[dataframe['up_down'] == '상승']['token']:\n",
    "                split = token.split(',')\n",
    "                count = 0\n",
    "                if len(split) > 1:\n",
    "                    for count in range(len(split)):\n",
    "                        up_ngram.extend(split[count])\n",
    "                    a += 1\n",
    "                    if a % 10000 == 0:\n",
    "                        print(a)\n",
    "            return up_ngram + up_token\n",
    "        \n",
    "def classify_neg_tokens(dataframe):\n",
    "    a= 0\n",
    "    for up_down in dataframe['up_down']:\n",
    "        if up_down == '하락':\n",
    "            down_ngram = []\n",
    "            for ngram in dataframe[dataframe['up_down'] == '하락']['ngrams']:\n",
    "                split = ngram.split(',')\n",
    "                count = 0\n",
    "                if len(split) > 1:\n",
    "                    for count in range(len(split)):\n",
    "                        down_ngram.extend(split[count])\n",
    "                    a += 1\n",
    "                    if a % 10000 == 0:\n",
    "                        print(a)\n",
    "            down_token = []\n",
    "            for token in dataframe[dataframe['up_down'] == '하락']['token']:\n",
    "                split = token.split(',')\n",
    "                count = 0\n",
    "                if len(split) > 1:\n",
    "                    for count in range(len(split)):\n",
    "                        up_ngram.expand(split[count])\n",
    "                    a += 1\n",
    "                    if a % 10000 == 0:\n",
    "                        print(a)\n",
    "            return down_ngram + down_token\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "added_df['ngram_token'] = 0\n",
    "added_df['ngrams'] = added_df['ngrams'].fillna(\"\")\n",
    "added_df['ngram_token'] = classify_pos_tokens(added_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(up_ngram), len(down_ngram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 병합작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "up_ngram_test = up_ngram\n",
    "down_ngram_test =down_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_ngram_test.extend(up_result)\n",
    "down_ngram_test.extend(down_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams['하락'] = pd.Series(down_ngram_test)\n",
    "ngrams['상승'] = pd.Series(up_ngram_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 극성 value_Counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_counts = ngrams['상승'].value_counts()\n",
    "down_counts = ngrams['하락'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams['up_ngrams'] = 0\n",
    "ngrams['up_ngrams'] = up_counts.to_frame().reset_index()\n",
    "ngrams['up_ngrams_counts'] = pd.Series(up_counts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams['down_ngrams'] = 0\n",
    "ngrams['down_ngrams'] = down_counts.to_frame().reset_index()\n",
    "ngrams['down_ngrams_counts'] = pd.Series(down_counts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15개 미만 잘라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams['상승'] = pd.Series(up_counts.loc[up_counts > 15])\n",
    "ngrams['하락'] = pd.Series(down_counts.loc[down_counts > 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams.rename_axis(index = 'ngram_id')\n",
    "ngrams.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_sum = ngrams['상승'].values.sum()\n",
    "down_sum = ngrams['하락'].values.sum()\n",
    "ngrams['up_score'] = ngrams['상승'].apply(lambda x: x/up_sum)\n",
    "ngrams['down_score'] = ngrams['하락'].apply(lambda x: x/down_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[2]/x[3]\n",
    "ngrams['polarity_score'] = ngrams.apply(lambda x: f(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 범위 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams[(ngrams['polarity_score'] < 0.73) | (ngrams['polarity_score'] > 1.3)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
