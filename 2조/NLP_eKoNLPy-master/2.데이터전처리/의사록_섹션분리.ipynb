{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 의사록 섹션 분리  \n",
    "\n",
    " - 괴상한 특수문자(.으로 잡지 못하는 특수문자)를 정규표현식을 이용하여 제거\n",
    " - 별도 제작한 정규표현식으로 섹션 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('tika\\\\금통위의사록(텍스트파일).xlsx', usecols = [1,2])\n",
    "data.columns = ['text', 'date']\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(data)):\n",
    "    data.loc[i, 'text'] = re.sub('- \\d+ -', '', data.loc[i, 'text'])\n",
    "    data.loc[i, 'text'] = re.sub('―|｢|｣|-|[․/→←+]', '', data.loc[i, 'text'])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_sentences(section):\n",
    "    sentence_enders = re.compile(r'((?<=[함음됨임봄짐움])+[ \\s\\n\\.;\\(]+|(?<=다)\\.)\\s+')\n",
    "    splits = list((m.start(), m.end()) for m in re.finditer(sentence_enders, section))\n",
    "    starts = [0] + [i[1] for i in splits]\n",
    "    ends = [i[0] for i in splits]\n",
    "    sentences = [section[start:end] for start, end in zip(starts[:-1], ends)]\n",
    "    for i, s in enumerate(sentences):\n",
    "        sentences[i] = (s.replace('\\n', ' ').replace(' ', ' ')) + '.'\n",
    "\n",
    "    text = '\\n'.join(sentences) if len(sentences) > 0 else ''\n",
    "    return sentences, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 섹션 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_split(data):\n",
    "    result_list = []\n",
    "    for i in range(len(data)):\n",
    "        time = data.loc[i, 'date']\n",
    "        text = data.loc[i, 'text']\n",
    "\n",
    "        p1 = re.search('(.?외환.?국제금융\\s?동향.?과 관련하여.*|\\(나\\) 외환.국제금융\\s?(및 금융시장)?\\s?동향)\\n?\\s*(일부 위원은|대부분의 위원들은)|｢?.?외환.?국제금융\\s?동향.?｣?과 관련하여.*' , text)\n",
    "        p2 = re.search('(.?금융시장\\s?동향.?과 관련하여,?|\\(다\\) 금융시장\\s?동향)\\n?\\s*일부 위원은|｢?.?금융시장\\s?동향.?｣?과 관련하여,?', text)\n",
    "        p3 = re.search('((\\((다|라)\\) )?.?통화정책\\s?방향.?에 관한 토론,?|이상과 같은 의견\\s?교환을 바탕으로.*통화정책\\s?방향.*에.*토론.*)\\n?', text)\n",
    "        \n",
    "        s1 = p1.start() if p1 else -1\n",
    "        s2 = p2.start() if p2 else -1\n",
    "        s3 = p3.start() if p2 else -1\n",
    "        \n",
    "        section_2 = text[s1:s2] if s1 >= 0 or s2 >= 0 else ''\n",
    "        section_3 = text[s2:s3] if s2 >= 0 or s3 >= 0 else ''\n",
    "        \n",
    "        sentences2, text2 = tidy_sentences(section_2)\n",
    "        sentences3, text3 = tidy_sentences(section_3)\n",
    "        new_dict = {\n",
    "            'date' : time,\n",
    "            's2' : text2,\n",
    "            's3' : text3\n",
    "        }\n",
    "        result_list.append(new_dict)\n",
    "        \n",
    "    df = pd.DataFrame(result_list)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
