{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, personalization=None, \n",
    "             max_iter=100, tol=1.0e-6, nstart=None, weight='weight', \n",
    "             dangling=None): \n",
    "    \"\"\"Return the PageRank of the nodes in the graph. \n",
    "  \n",
    "    PageRank computes a ranking of the nodes in the graph G based on \n",
    "    the structure of the incoming links. It was originally designed as \n",
    "    an algorithm to rank web pages. \n",
    "  \n",
    "    Parameters \n",
    "    ---------- \n",
    "    G : graph \n",
    "      A NetworkX graph.  Undirected graphs will be converted to a directed \n",
    "      graph with two directed edges for each undirected edge. \n",
    "  \n",
    "    alpha : float, optional \n",
    "      Damping parameter for PageRank, default=0.85. \n",
    "  \n",
    "    personalization: dict, optional \n",
    "      The \"personalization vector\" consisting of a dictionary with a \n",
    "      key for every graph node and nonzero personalization value for each node. \n",
    "      By default, a uniform distribution is used. \n",
    "  \n",
    "    max_iter : integer, optional \n",
    "      Maximum number of iterations in power method eigenvalue solver. \n",
    "  \n",
    "    tol : float, optional \n",
    "      Error tolerance used to check convergence in power method solver. \n",
    "  \n",
    "    nstart : dictionary, optional \n",
    "      Starting value of PageRank iteration for each node. \n",
    "  \n",
    "    weight : key, optional \n",
    "      Edge data key to use as weight.  If None weights are set to 1. \n",
    "  \n",
    "    dangling: dict, optional \n",
    "      The outedges to be assigned to any \"dangling\" nodes, i.e., nodes without \n",
    "      any outedges. The dict key is the node the outedge points to and the dict \n",
    "      value is the weight of that outedge. By default, dangling nodes are given \n",
    "      outedges according to the personalization vector (uniform if not \n",
    "      specified). This must be selected to result in an irreducible transition \n",
    "      matrix (see notes under google_matrix). It may be common to have the \n",
    "      dangling dict to be the same as the personalization dict. \n",
    "  \n",
    "    Returns \n",
    "    ------- \n",
    "    pagerank : dictionary \n",
    "       Dictionary of nodes with PageRank as value \n",
    "  \n",
    "    Notes \n",
    "    ----- \n",
    "    The eigenvector calculation is done by the power iteration method \n",
    "    and has no guarantee of convergence.  The iteration will stop \n",
    "    after max_iter iterations or an error tolerance of \n",
    "    number_of_nodes(G)*tol has been reached. \n",
    "  \n",
    "    The PageRank algorithm was designed for directed graphs but this \n",
    "    algorithm does not check if the input graph is directed and will \n",
    "    execute on undirected graphs by converting each edge in the \n",
    "    directed graph to two edges. \n",
    "  \n",
    "      \n",
    "    \"\"\"\n",
    "    if len(G) == 0: \n",
    "        return {} \n",
    "  \n",
    "    if not G.is_directed(): \n",
    "        D = G.to_directed() \n",
    "    else: \n",
    "        D = G \n",
    "  \n",
    "    # Create a copy in (right) stochastic form \n",
    "    W = nx.stochastic_graph(D, weight=weight) \n",
    "    N = W.number_of_nodes() \n",
    "  \n",
    "    # Choose fixed starting vector if not given \n",
    "    if nstart is None: \n",
    "        x = dict.fromkeys(W, 1.0 / N) \n",
    "    else: \n",
    "        # Normalized nstart vector \n",
    "        s = float(sum(nstart.values())) \n",
    "        x = dict((k, v / s) for k, v in nstart.items()) \n",
    "  \n",
    "    if personalization is None: \n",
    "  \n",
    "        # Assign uniform personalization vector if not given \n",
    "        p = dict.fromkeys(W, 1.0 / N) \n",
    "    else: \n",
    "        missing = set(G) - set(personalization) \n",
    "        if missing: \n",
    "            raise NetworkXError('Personalization dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing) \n",
    "        s = float(sum(personalization.values())) \n",
    "        p = dict((k, v / s) for k, v in personalization.items()) \n",
    "  \n",
    "    if dangling is None: \n",
    "  \n",
    "        # Use personalization vector if dangling vector not specified \n",
    "        dangling_weights = p \n",
    "    else: \n",
    "        missing = set(G) - set(dangling) \n",
    "        if missing: \n",
    "            raise NetworkXError('Dangling node dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing) \n",
    "        s = float(sum(dangling.values())) \n",
    "        dangling_weights = dict((k, v/s) for k, v in dangling.items()) \n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0] \n",
    "  \n",
    "    # power iteration: make up to max_iter iterations \n",
    "    for _ in range(max_iter): \n",
    "        xlast = x \n",
    "        x = dict.fromkeys(xlast.keys(), 0) \n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes) \n",
    "        for n in x: \n",
    "  \n",
    "            # this matrix multiply looks odd because it is \n",
    "            # doing a left multiply x^T=xlast^T*W \n",
    "            for nbr in W[n]: \n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight] \n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n] \n",
    "  \n",
    "        # check convergence, l1 norm \n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x]) \n",
    "        if err < N*tol: \n",
    "            return x \n",
    "    raise NetworkXError('pagerank: power iteration failed to converge '\n",
    "                        'in %d iterations.' % max_iter) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "G=nx.barabasi_albert_graph(4,2) \n",
    "pr=nx.pagerank(G,0.85) \n",
    "pr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P Sf (A) = 1, P Sf (B) = 2, P Sf (C) = 3, P Sf (D) = 4\n",
    "NSf (A) = 3, P Cf (B, A) = 3, P Cf (B, C) = 7\n",
    "P Cf (B, D) = 3, P Cf (A, C) = 2, NCf (B, C) = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_edge('A', 'B', weight=3)\n",
    "G.add_edge('C', 'A', weight=2)\n",
    "G.add_edge('C', 'B', weight=3.5)\n",
    "G.add_edge('D', 'B', weight=3)\n",
    "pr=nx.pagerank(G)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.05269320921748135,\n",
       " 'B': 0.8208169953923542,\n",
       " 'C': 0.05357142941698917,\n",
       " 'D': 0.07291836597317511}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "G.add_edge('A','A', weight=1/3)\n",
    "G.add_edge('B','B', weight=2)\n",
    "G.add_edge('C','C', weight=3)\n",
    "G.add_edge('D','D', weight=4)\n",
    "\"===========================\"\n",
    "G.add_edge('A', 'B', weight=3)\n",
    "G.add_edge('C', 'A', weight=2)\n",
    "G.add_edge('C', 'B', weight=3.5)\n",
    "G.add_edge('D', 'B', weight=3)\n",
    "pr=nx.pagerank(G)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052693</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.072918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  0.052693  0.820817  0.053571  0.072918"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([pr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `G` not found.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 0.47973057398636304,\n",
       " 'A': 0.054615857445494694,\n",
       " 'C': 0.4110377111226474,\n",
       " 'D': 0.05461585744549469}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "# G.add_edge('A', 'A', weight=1/3)\n",
    "# G.add_edge('B', 'B', weight=1000000)\n",
    "# G.add_edge('C', 'C', weight=0.00001)\n",
    "# G.add_edge('D', 'D', weight=4)\n",
    "G.add_edge('B', 'A', weight=CA)\n",
    "G.add_edge('A', 'C', weight=CB)\n",
    "G.add_edge('B', 'C', weight=CC)\n",
    "G.add_edge('B', 'D', weight=CD)\n",
    "# G.add_node('A', weight=1/3)\n",
    "# G.add_node('B', weight=2)\n",
    "# G.add_node('C', weight=3)\n",
    "# G.add_node('D', weight=4)\n",
    "pr=nx.pagerank(G)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.clear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
